# âœï¸ Prompt Authoring Workflow & Moderation Queue

**Owner:** Aubert

Memoraâ€™s Companion relies on carefully crafted prompts â€” written in multiple languages, tones, and contexts â€” to guide learning, reflection, memory, and care. This workflow governs how prompts are created, reviewed, approved, translated, and monitored post-deployment to ensure **consistency, safety, and dignity** in every user interaction.

---

## ğŸ¯ Goals

- Ensure all prompts are **purpose-aligned**, **tone-matched**, and **ethically sound**
- Enable multilingual, culturally attuned authoring with **trauma-aware filters**
- Maintain clear audit trails for versioning, edits, moderation, and red flags
- Allow for **studio-level oversight** with local partner feedback integration
- Prevent prompt drift, ethical mismatches, and overexposure to triggering content

---

## ğŸ› ï¸ Authoring Workflow (End-to-End)

| Stage | Action | Owner |
| --- | --- | --- |
| ğŸ“ **Prompt Drafting** | Draft prompt with metadata: tone, audience, goal, language | Prompt Author (internal or partner) |
| ğŸ” **Peer Review (Stage 1)** | Initial review for clarity, structure, goal fit | Studio QA Reviewer |
| ğŸ›¡ï¸ **Ethical Screening (Stage 2)** | Checks against trauma triggers, neurodivergence flags, tone misalignment | Ethics QA Team |
| ğŸŒ **Localization Pass** | Translate and adapt for region/language â€” not literal translation | Localization Manager |
| ğŸ”„ **Companion Simulation Test** | Prompt tested in Companion emulator for voice rendering + flow impact | Behavioral QA |
| âœ… **Final Approval** | Locked for deployment; tagged by region, Companion mode, version | Studio Lead |
| ğŸ§¾ **Deployment Assignment** | Added to Prompt Library subset(s) by module (e.g. Resilience, Grief, Curiosity) | Product Ops |

---

## ğŸ§¾ Prompt Metadata (Logged Per Entry)

| Field | Description |
| --- | --- |
| âœï¸ Author | Name, date, role |
| ğŸ§  Goal | Cognitive / Emotional / Reflective / Learning |
| ğŸ­ Tone Tag | Gentle, Uplifting, Curious, Reassuring, Culturally Neutral |
| ğŸ§© Prompt Type | Open-ended, Reframing, Anchoring, Directive, Playful |
| ğŸŒ Language & Region | e.g., Swahili â€“ Kenya; French â€“ Quebec; English â€“ Urban Canada |
| ğŸ”’ Privacy Tier | Public / Shadow / Private |
| ğŸ›¡ï¸ Trigger Review Score | 0â€“3 risk score (automated + human screening) |
| ğŸ“˜ Companion Mode | Youth, Elder, Grief Support, etc. |

---

## ğŸ§­ Moderation Queue System

All new or edited prompts enter a moderation queue before being eligible for deployment.

| Queue Type | Contents |
| --- | --- |
| ğŸš¦ **Draft Queue** | New prompts awaiting peer review |
| ğŸ§ª **Test Queue** | Prompts passing peer review, undergoing Companion simulation |
| âš ï¸ **Ethics Queue** | Prompts flagged for content concern (internal or field-sourced) |
| ğŸŒ€ **Localization Queue** | Prompts ready for or awaiting translation |
| ğŸ” **Version Review Queue** | Legacy prompts up for update, tone re-calibration, or archival |
| âŒ **Rejection Bin** | Deleted or archived prompts (never deployed) |

> Queue activity is tracked by prompt ID, status, reviewers, and timestamp.

---

## ğŸ“Œ Prompt Lifecycle States

| State | Description |
| --- | --- |
| âœï¸ Draft | In authoring or awaiting peer review |
| ğŸ” In Review | Under moderation (Stage 1 or 2) |
| ğŸ§¬ Localizing | Approved but pending region/language adaptation |
| âœ… Approved | Live in one or more Companion flows |
| ğŸ” Under Revision | Pulled for tone drift, field flag, or misfire |
| âŒ Archived | Retired and replaced |
| ğŸš« Rejected | Removed for failure to meet tone/ethics standards |

---

## ğŸ§  Companion Voice Sim Preview

Each prompt undergoes **real-time voice rendering** using Companion tone packs before deployment to test:
- Sentence cadence
- Emotional balance
- Multi-prompt transitions
- Fit with memory anchors
- Natural UX flow for children, elders, multilingual users

> Misfires here auto-route back to moderation.

---

## ğŸ“Š Analytics & Drift Detection

| Metric | Description |
| --- | --- |
| ğŸ“ˆ Usage Frequency | How often prompt is triggered across deployments |
| ğŸ’¬ Reflection Match Rate | % of user responses engaging with prompt as intended |
| âš ï¸ Misfire Reports | Field tags for confusion, disengagement, or distress |
| ğŸ¯ Impact Weighting | Based on follow-through, emotional response, session continuation |
| ğŸ” Drift Score | Deviation from original tone over time (based on Companion logs + NLP scan) |

---

## ğŸ” Feedback Loop Integration

Prompts flagged by:
- NGO field staff
- Caregivers or users (via optional UX triggers)
- Studio QA post-deployment reviews
- Companion tone drift logs

â€¦are automatically re-routed to the **Ethics Queue**, tagged for moderation, and paused if severity meets threshold.

---

## âœ… Readiness Checklist Before Deployment

| Checkpoint | Status |
| --- | --- |
| Peer review signed off | âœ… |
| Ethics risk < 2 | âœ… |
| Companion tone tested | âœ… |
| Localization approved | âœ… |
| Field use scope tagged | âœ… |
| Prompt ID and metadata logged | âœ… |

---

## ğŸ—‚ Prompt Libraries by Module (Examples)

- ğŸ’ Youth Curiosity & Confidence
- ğŸŒ± Emotional Recovery & Reflection
- ğŸ§­ Trauma Navigation & Anchoring
- ğŸ“˜ Literacy Growth & Learning Motivation
- ğŸ§“ Dementia Routine & Safety
- ğŸ§  Grief Processing & Memory Loop
- ğŸ—£ Multilingual & Culturally Adaptive Frames
